{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Target**: 99.4% validation accuracy\n",
        "\n",
        "**Explanation for the Target**: This iteration will introduce Global Average Pooling to the model. The last iteration showed a severly underfitted model, liekly due to introduction of btach normalization and dropout. We can reduce it by reducing the DropOut rate to 0.05. We will also move the pooling layer to receptive field 5, as patterns are recognized at that layer. The last model also had some extra room for parameters. We will increase the parameter count slightly to make use of the target parameters. We are hoping to achieve the final targeted accuracy of this assignment.\n",
        "\n",
        "**Result**:\n",
        "\n",
        "Max Training Accuracy: 98.85%\n",
        "\n",
        "Max Validation Accuracy: 99.49%\n",
        "\n",
        "\n",
        "**Analysis**: We see the accuracy revolves around 99.4% in the final epochs. It is safe to say that we have achieved the target."
      ],
      "metadata": {
        "id": "Cs7iMWSTIec_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m2JWFliFfKT"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_Cx9q2QFgM7"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # CONVOLUTION BLOCK #1\n",
        "        self.convblock1 = nn.Sequential( # 28x28 > 28x28 | RF 3 | jout=1\n",
        "          nn.Conv2d(1, 10, 3, padding=1), \n",
        "          nn.ReLU(),\n",
        "          nn.BatchNorm2d(10),\n",
        "          nn.Dropout2d(0.05)\n",
        "        )   \n",
        "        self.convblock2 = nn.Sequential( # 28x28 > 28x28 | RF 5 | jout=1\n",
        "          nn.Conv2d(10, 16, 3, padding=1), \n",
        "          nn.ReLU(),\n",
        "          nn.BatchNorm2d(16),\n",
        "          nn.Dropout2d(0.05)\n",
        "        )\n",
        "        # TRANSITIONAL BLOCK #1        \n",
        "        self.pool1 = nn.MaxPool2d(2, 2) # 28x28 > 14x14 | RF 6 | jout=1\n",
        "        self.convblock3 = nn.Sequential( # 14x14 > 14x14 | RF 6 | jout=2\n",
        "          nn.Conv2d(16, 8, 1),\n",
        "          nn.ReLU(),\n",
        "          nn.BatchNorm2d(8),\n",
        "          nn.Dropout2d(0.05)\n",
        "        )\n",
        "\n",
        "        # CONVOLUTION BLOCK #2\n",
        "        self.convblock4 = nn.Sequential( # 14x14 > 14x14 | RF 10 | jout=2\n",
        "          nn.Conv2d(8, 16, 3, padding=1), \n",
        "          nn.ReLU(),\n",
        "          nn.BatchNorm2d(16),\n",
        "          nn.Dropout2d(0.05)\n",
        "        )\n",
        "\n",
        "        self.convblock5 = nn.Sequential( # 14x14 > 14x14 | RF 14 | jout=2\n",
        "          nn.Conv2d(16, 16, 3, padding=1),\n",
        "          nn.ReLU(),\n",
        "          nn.BatchNorm2d(16),\n",
        "          nn.Dropout2d(0.05)\n",
        "        )\n",
        "        self.convblock6 = nn.Sequential( # 14x14 > 14x14 | RF 18 | jout=2\n",
        "          nn.Conv2d(16, 16, 3, padding=1),\n",
        "          nn.ReLU(),\n",
        "          nn.BatchNorm2d(16),\n",
        "          nn.Dropout2d(0.05)\n",
        "        )\n",
        "        # TRANSITIONAL BLOCK #2    \n",
        "        self.pool2 = nn.MaxPool2d(2, 2) # 14x14 > 7x7 | RF 20 | jout=2\n",
        "        self.convblock7 = nn.Sequential( # 7x7 > 7x7 | RF 20 | jout=3\n",
        "          nn.Conv2d(16, 8, 1),\n",
        "          nn.ReLU(),\n",
        "          nn.BatchNorm2d(8),\n",
        "          nn.Dropout2d(0.05)\n",
        "        )\n",
        "        #CONVOLUTIONAL BLOCK #3\n",
        "        self.convblock8 = nn.Sequential( #7x7 > 5x5 | RF 26 | jout=3\n",
        "            nn.Conv2d(8, 10, 3),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(10),\n",
        "            nn.Dropout2d(0.05)\n",
        "        )\n",
        "        self.convblock9 = nn.Sequential( #5x5 > 3x3 | RF 32 | jout=3\n",
        "            nn.Conv2d(10, 16, 3),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.Dropout2d(0.05)\n",
        "        )\n",
        "        self.convblock10 = nn.Sequential( #3x3 > 3x3 | RF 38 | jout=3\n",
        "            nn.Conv2d(16, 10, 1)\n",
        "            #nn.ReLU(),\n",
        "            #nn.BatchNorm2d(10),\n",
        "            #nn.Dropout2d(0.1)\n",
        "        )\n",
        "        self.gap = nn.Sequential( #3x3 > 1x1 | RF 42 | jout=3\n",
        "            nn.AvgPool2d(kernel_size=3)\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convblock1(x)\n",
        "        x = self.convblock2(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.convblock3(x)\n",
        "        x = self.convblock4(x)\n",
        "        x = self.convblock5(x)\n",
        "        x = self.convblock6(x)\n",
        "        x = self.pool2(x)\n",
        "        x = self.convblock7(x)\n",
        "        x = self.convblock8(x)\n",
        "        x = self.convblock9(x)\n",
        "        x = self.convblock10(x)\n",
        "        x = self.gap(x)\n",
        "      \n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdydjYTZFyi3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10cf3ee8-4336-4984-80c7-15afb673fafe"
      },
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.8/dist-packages (1.5.1)\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 10, 28, 28]             100\n",
            "              ReLU-2           [-1, 10, 28, 28]               0\n",
            "       BatchNorm2d-3           [-1, 10, 28, 28]              20\n",
            "         Dropout2d-4           [-1, 10, 28, 28]               0\n",
            "            Conv2d-5           [-1, 16, 28, 28]           1,456\n",
            "              ReLU-6           [-1, 16, 28, 28]               0\n",
            "       BatchNorm2d-7           [-1, 16, 28, 28]              32\n",
            "         Dropout2d-8           [-1, 16, 28, 28]               0\n",
            "         MaxPool2d-9           [-1, 16, 14, 14]               0\n",
            "           Conv2d-10            [-1, 8, 14, 14]             136\n",
            "             ReLU-11            [-1, 8, 14, 14]               0\n",
            "      BatchNorm2d-12            [-1, 8, 14, 14]              16\n",
            "        Dropout2d-13            [-1, 8, 14, 14]               0\n",
            "           Conv2d-14           [-1, 16, 14, 14]           1,168\n",
            "             ReLU-15           [-1, 16, 14, 14]               0\n",
            "      BatchNorm2d-16           [-1, 16, 14, 14]              32\n",
            "        Dropout2d-17           [-1, 16, 14, 14]               0\n",
            "           Conv2d-18           [-1, 16, 14, 14]           2,320\n",
            "             ReLU-19           [-1, 16, 14, 14]               0\n",
            "      BatchNorm2d-20           [-1, 16, 14, 14]              32\n",
            "        Dropout2d-21           [-1, 16, 14, 14]               0\n",
            "           Conv2d-22           [-1, 16, 14, 14]           2,320\n",
            "             ReLU-23           [-1, 16, 14, 14]               0\n",
            "      BatchNorm2d-24           [-1, 16, 14, 14]              32\n",
            "        Dropout2d-25           [-1, 16, 14, 14]               0\n",
            "        MaxPool2d-26             [-1, 16, 7, 7]               0\n",
            "           Conv2d-27              [-1, 8, 7, 7]             136\n",
            "             ReLU-28              [-1, 8, 7, 7]               0\n",
            "      BatchNorm2d-29              [-1, 8, 7, 7]              16\n",
            "        Dropout2d-30              [-1, 8, 7, 7]               0\n",
            "           Conv2d-31             [-1, 10, 5, 5]             730\n",
            "             ReLU-32             [-1, 10, 5, 5]               0\n",
            "      BatchNorm2d-33             [-1, 10, 5, 5]              20\n",
            "        Dropout2d-34             [-1, 10, 5, 5]               0\n",
            "           Conv2d-35             [-1, 16, 3, 3]           1,456\n",
            "             ReLU-36             [-1, 16, 3, 3]               0\n",
            "      BatchNorm2d-37             [-1, 16, 3, 3]              32\n",
            "        Dropout2d-38             [-1, 16, 3, 3]               0\n",
            "           Conv2d-39             [-1, 10, 3, 3]             170\n",
            "        AvgPool2d-40             [-1, 10, 1, 1]               0\n",
            "================================================================\n",
            "Total params: 10,224\n",
            "Trainable params: 10,224\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.01\n",
            "Params size (MB): 0.04\n",
            "Estimated Total Size (MB): 1.05\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-47-f48de782f4be>:95: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqTWLaM5GHgH"
      },
      "source": [
        "\n",
        "\n",
        "torch.manual_seed(1)\n",
        "batch_size = 64\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        #transforms.RandomRotation((-7.0, 7.0), fill=(1,)),\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fDefDhaFlwH"
      },
      "source": [
        "from tqdm import tqdm\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    correct = 0\n",
        "    processed = 0\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        y_pred = model(data)\n",
        "        pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "        processed += len(data)\n",
        "\n",
        "        pbar.set_description(desc= f'Epoch={epoch} Loss={loss.item()} batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}%')\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMWbLWO6FuHb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54d820b9-c9e1-4655-aac6-51b3b6006f89"
      },
      "source": [
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "\n",
        "\n",
        "for epoch in range(1, 16):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    #scheduler.step()\n",
        "    test(model, device, test_loader)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/938 [00:00<?, ?it/s]<ipython-input-47-f48de782f4be>:95: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n",
            "Epoch=1 Loss=0.14346933364868164 batch_id=937 Accuracy=90.11%: 100%|██████████| 938/938 [00:25<00:00, 37.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0447, Accuracy: 9853/10000 (98.53%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch=2 Loss=0.028531590476632118 batch_id=937 Accuracy=97.17%: 100%|██████████| 938/938 [00:24<00:00, 38.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0376, Accuracy: 9888/10000 (98.88%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch=3 Loss=0.16348429024219513 batch_id=937 Accuracy=97.68%: 100%|██████████| 938/938 [00:24<00:00, 38.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0303, Accuracy: 9910/10000 (99.10%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch=4 Loss=0.03897513076663017 batch_id=937 Accuracy=97.93%: 100%|██████████| 938/938 [00:24<00:00, 38.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0274, Accuracy: 9911/10000 (99.11%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch=5 Loss=0.009880609810352325 batch_id=937 Accuracy=98.10%: 100%|██████████| 938/938 [00:24<00:00, 38.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0260, Accuracy: 9917/10000 (99.17%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch=6 Loss=0.033547207713127136 batch_id=937 Accuracy=98.29%: 100%|██████████| 938/938 [00:24<00:00, 38.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0256, Accuracy: 9923/10000 (99.23%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch=7 Loss=0.05691586434841156 batch_id=937 Accuracy=98.35%: 100%|██████████| 938/938 [00:24<00:00, 38.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0248, Accuracy: 9928/10000 (99.28%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch=8 Loss=0.15364857017993927 batch_id=937 Accuracy=98.47%: 100%|██████████| 938/938 [00:24<00:00, 38.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0238, Accuracy: 9923/10000 (99.23%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch=9 Loss=0.06393135339021683 batch_id=937 Accuracy=98.46%: 100%|██████████| 938/938 [00:24<00:00, 38.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0216, Accuracy: 9939/10000 (99.39%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch=10 Loss=0.1645202338695526 batch_id=937 Accuracy=98.63%: 100%|██████████| 938/938 [00:25<00:00, 37.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0201, Accuracy: 9925/10000 (99.25%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch=11 Loss=0.020322799682617188 batch_id=937 Accuracy=98.64%: 100%|██████████| 938/938 [00:24<00:00, 38.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0195, Accuracy: 9940/10000 (99.40%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch=12 Loss=0.022528648376464844 batch_id=937 Accuracy=98.68%: 100%|██████████| 938/938 [00:24<00:00, 38.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0193, Accuracy: 9949/10000 (99.49%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch=13 Loss=0.031043240800499916 batch_id=937 Accuracy=98.83%: 100%|██████████| 938/938 [00:24<00:00, 38.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0209, Accuracy: 9933/10000 (99.33%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch=14 Loss=0.19452056288719177 batch_id=937 Accuracy=98.85%: 100%|██████████| 938/938 [00:24<00:00, 38.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0197, Accuracy: 9937/10000 (99.37%)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch=15 Loss=0.08037396520376205 batch_id=937 Accuracy=98.82%: 100%|██████████| 938/938 [00:24<00:00, 38.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0179, Accuracy: 9946/10000 (99.46%)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}